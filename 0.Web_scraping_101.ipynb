{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3acacfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a13bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL artikel yang akan di-scrape\n",
    "url = 'https://www.tempo.co/ekonomi/seknas-fitra-makan-bergizi-gratis-belum-dongkrak-pertumbuhan-ekonomi-1533866'\n",
    "\n",
    "# Mengirim permintaan HTTP ke URL\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Menyimpan hasil scraping di dictionary\n",
    "hasil = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendapatkan judul berita\n",
    "judul = soup.find('h1', class_='text-[26px] font-bold leading-[122%] text-neutral-1200')\n",
    "hasil['judul'] = judul.get_text(strip=True) if judul else 'Tidak ditemukan'\n",
    "\n",
    "# Mendapatkan sub-judul berita\n",
    "sub_judul = soup.find('div', class_='font-roboserif leading-[156%] text-neutral-1100')\n",
    "hasil['sub_judul'] = sub_judul.get_text(strip=True) if sub_judul else 'Tidak ditemukan'\n",
    "\n",
    "# Mendapatkan isi berita\n",
    "isi_paragraf = []\n",
    "isi_berita = soup.find_all('div', id='content-wrapper', class_='max-lg:container xl')\n",
    "\n",
    "for i in isi_berita:\n",
    "    paragraf = i.find_all('p')\n",
    "    for p in paragraf:\n",
    "        teks = p.get_text(strip=True)\n",
    "        if teks:  #menambahkan teks bila ada\n",
    "            isi_paragraf.append(teks)\n",
    "ringkasan = '\\n\\n'.join(isi_paragraf)\n",
    "hasil['isi'] = ringkasan if ringkasan else 'Tidak ditemukan'\n",
    "\n",
    "# Mendapatkan tanggal publikasi\n",
    "tanggal_publikasi = soup.find('p', class_='text-neutral-900 text-sm').get_text(strip=True)\n",
    "if isinstance(tanggal_publikasi, str):\n",
    "    tanggal, jam = [part.strip() for part in upload.split('|')]\n",
    "hasil['tanggal'] = tanggal if tanggal else 'Tidak ditemukan'\n",
    "hasil['jam'] = jam if jam else 'Tidak ditemukan'\n",
    "\n",
    "# Mendapatkan kategori berita\n",
    "kategori = soup.find('span', class_='text-sm font-medium text-primary-main')\n",
    "hasil['kategori'] = kategori.get_text(strip=True) if kategori else 'Tidak ditemukan' \n",
    "\n",
    "# Menampilkan hasil dari dictionary (kat = kategori, res = result)\n",
    "for kat, res in hasil.items():\n",
    "    print(f\"{kat.capitalize()}: {res}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b62eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
