{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fabefde",
   "metadata": {},
   "source": [
    "## 0. Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba136f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pandas==2.2.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: requests==2.31.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: selenium==4.21.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 5)) (4.21.0)\n",
      "Requirement already satisfied: tqdm==4.66.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 6)) (4.66.4)\n",
      "Requirement already satisfied: urllib3==1.26.20 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 7)) (1.26.20)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from beautifulsoup4==4.12.3->-r requirements.txt (line 1)) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas==2.2.2->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas==2.2.2->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas==2.2.2->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests==2.31.0->-r requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests==2.31.0->-r requirements.txt (line 4)) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests==2.31.0->-r requirements.txt (line 4)) (2024.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from selenium==4.21.0->-r requirements.txt (line 5)) (0.25.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from selenium==4.21.0->-r requirements.txt (line 5)) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from selenium==4.21.0->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm==4.66.4->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from trio~=0.17->selenium==4.21.0->-r requirements.txt (line 5)) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from trio~=0.17->selenium==4.21.0->-r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from trio~=0.17->selenium==4.21.0->-r requirements.txt (line 5)) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from trio~=0.17->selenium==4.21.0->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from trio~=0.17->selenium==4.21.0->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from trio-websocket~=0.9->selenium==4.21.0->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from urllib3[socks]<3,>=1.26->selenium==4.21.0->-r requirements.txt (line 5)) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from cffi>=1.14->trio~=0.17->selenium==4.21.0->-r requirements.txt (line 5)) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium==4.21.0->-r requirements.txt (line 5)) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\user\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## jalankan ini dahulu sebelum running\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadb752",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup #scraping web statis\n",
    "import time\n",
    "from tqdm import tqdm #info progress\n",
    "\n",
    "## selenium, scraping web dinamis\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from urllib.parse import quote_plus #parsing string \"spasi\" menjadi \"+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23bd6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "## check if there is a response, if it's 200, we are good to go\n",
    "s = requests.Session()\n",
    "url = 'https://www.tempo.co/search?q=makan+bergizi+gratis&page=1'\n",
    "response = s.get(url)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d65819",
   "metadata": {},
   "source": [
    "## 1. Scraping satu artikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fungsi melakukan scraping data 1 halaman Tempo, masukkan string url\n",
    "def scrape_tempo(url: str) -> pd.DataFrame: \n",
    "    ## Inisiasi dictionary hasil\n",
    "    hasil = {}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        ##Judul\n",
    "        judul = soup.find('h1', class_='text-[26px] font-bold leading-[122%] text-neutral-1200')\n",
    "        hasil['judul'] = judul.get_text(strip=True) if judul else np.nan\n",
    "\n",
    "        ## Sub judul\n",
    "        sub_judul = soup.find('div', class_='font-roboserif leading-[156%] text-neutral-1100')\n",
    "        hasil['sub_judul'] = sub_judul.get_text(strip=True) if sub_judul else np.nan\n",
    "\n",
    "        ## Isi berita\n",
    "        isi_paragraf = []\n",
    "        isi_berita = soup.find_all('div', id='content-wrapper', class_='max-lg:container xl')\n",
    "\n",
    "        for i in isi_berita:\n",
    "            paragraf = i.find_all('p')\n",
    "            for p in paragraf:\n",
    "                teks = p.get_text(strip=True)\n",
    "                if teks:  #menambahkan teks bila ada\n",
    "                    isi_paragraf.append(teks)\n",
    "        ringkasan = '\\n\\n'.join(isi_paragraf)\n",
    "        hasil['isi'] = ringkasan if ringkasan else np.nan\n",
    "\n",
    "        ## Tanggal & Jam publikasi\n",
    "        tanggal_publikasi = soup.find('p', class_='text-neutral-900 text-sm')\n",
    "        if tanggal_publikasi:\n",
    "            waktu = tanggal_publikasi.get_text(strip=True)\n",
    "            if '|' in waktu:\n",
    "                tanggal, jam = [part.strip() for part in waktu.split('|')]\n",
    "                hasil['tanggal'] = tanggal\n",
    "                hasil['jam'] = jam\n",
    "            else:\n",
    "                hasil['tanggal'] = waktu\n",
    "                hasil['jam'] = np.nan\n",
    "        else:\n",
    "            hasil['tanggal'] = np.nan\n",
    "            hasil['jam'] = np.nan\n",
    "\n",
    "        ## Kategori\n",
    "        kategori = soup.find('span', class_='text-sm font-medium text-primary-main')\n",
    "        hasil['kategori'] = kategori.get_text(strip=True) if kategori else np.nan\n",
    "\n",
    "        ## Link\n",
    "        hasil['link'] = url \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi kesalahan saat scraping: {e}\")\n",
    "        return None\n",
    "\n",
    "    ## Kembalikan juga sebagai DataFrame\n",
    "    df = pd.DataFrame([hasil])\n",
    "    # print('selesai scraping')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a04d85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>sub_judul</th>\n",
       "      <th>isi</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>jam</th>\n",
       "      <th>kategori</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Potensi Masalah dari Rencana Pemerintah Ubah L...</td>\n",
       "      <td>Rencana ini berpotensi melanggar hak asasi par...</td>\n",
       "      <td>TEMPO.CO,Jakarta- Menteri Perumahan dan Kawasa...</td>\n",
       "      <td>24 Mei 2025</td>\n",
       "      <td>21.00 WIB</td>\n",
       "      <td>Bisnis</td>\n",
       "      <td>https://www.tempo.co/ekonomi/potensi-masalah-d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Potensi Masalah dari Rencana Pemerintah Ubah L...   \n",
       "\n",
       "                                           sub_judul  \\\n",
       "0  Rencana ini berpotensi melanggar hak asasi par...   \n",
       "\n",
       "                                                 isi      tanggal        jam  \\\n",
       "0  TEMPO.CO,Jakarta- Menteri Perumahan dan Kawasa...  24 Mei 2025  21.00 WIB   \n",
       "\n",
       "  kategori                                               link  \n",
       "0   Bisnis  https://www.tempo.co/ekonomi/potensi-masalah-d...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.tempo.co/ekonomi/potensi-masalah-dari-rencana-pemerintah-ubah-lapas-jadi-perumahan-1533913'\n",
    "df_hasil = scrape_tempo(url)\n",
    "df_hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "868f5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil.to_csv('./files/tempo_satu_artikel.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1679f977",
   "metadata": {},
   "source": [
    "## 2. Crawling URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8954ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fungsi melakukan scraping URL Tempo, masukkan string keyword dan max halaman\n",
    "def scrape_tempo_search_selenium(kata_kunci: str, halaman: int) -> pd.DataFrame: \n",
    "    # Set User-Agent\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'\n",
    "    opts = Options()\n",
    "    opts.add_argument(f\"user-agent={user_agent}\")\n",
    "    opts.add_argument(\"--headless\")\n",
    "    opts.add_argument(\"--no-sanbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "        \n",
    "    # Parameter input\n",
    "    keyword = kata_kunci #contoh: \"makan bergizi gratis\"\n",
    "    max_pages = halaman #contoh: 2\n",
    "    results = []\n",
    "\n",
    "    # Loop halaman\n",
    "    for page in tqdm(range(1, max_pages + 1)):\n",
    "        # print(f\"Scraping page {page}...\")\n",
    "\n",
    "        # Format URL pencarian\n",
    "        encoded_query = quote_plus(keyword)\n",
    "        url = f\"https://www.tempo.co/search?q={encoded_query}&page={page}\"\n",
    "        \n",
    "        driver.get(url)\n",
    "        time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            container = driver.find_element(\"css selector\", \"div.flex.flex-col.divide-y.divide-neutral-500\")\n",
    "            beritas = container.find_elements(\"css selector\", \"figure.flex.flex-row.gap-3.py-4.container.lg\\\\:mx-0.lg\\\\:px-0\")\n",
    "            for berita in beritas:\n",
    "                try:\n",
    "                    a = berita.find_element(\"tag name\", \"a\")\n",
    "                    p = berita.find_element(\"tag name\", \"p\")\n",
    "                    results.append({\n",
    "                        \"judul\": p.text,\n",
    "                        \"link\": a.get_attribute(\"href\")\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(\"Skip 1 berita:\", e)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Skip page:\", e)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Simpan ke DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"./files/tempo_links.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(\"Selesai. Total berita:\", len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b6ac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:57<00:00, 11.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selesai. Total berita: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seknas Fitra: Makan Bergizi Gratis Belum Dongk...</td>\n",
       "      <td>https://www.tempo.co/ekonomi/seknas-fitra-maka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hingga 21 Mei, Anggaran Makan Bergizi Gratis S...</td>\n",
       "      <td>https://www.tempo.co/ekonomi/hingga-21-mei-ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Korban Keracunan MBG Lebih Besar dari Klaim Pr...</td>\n",
       "      <td>https://www.tempo.co/politik/korban-keracunan-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sejumlah Titik Kritis dalam Program MBG, Menur...</td>\n",
       "      <td>https://www.tempo.co/politik/sejumlah-titik-kr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bos BGN Membantah Raffi Ahmad Kelola 300 Dapur...</td>\n",
       "      <td>https://www.tempo.co/ekonomi/bos-bgn-membantah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Penerima Manfaat Makan Bergizi Gratis hingga M...</td>\n",
       "      <td>https://www.tempo.co/ekonomi/penerima-manfaat-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Peluncuran Dapur Satuan Pelayanan Pemenuhan Gizi</td>\n",
       "      <td>https://www.tempo.co/foto/arsip/peluncuran-dap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Cari Sebab Penerimaan Pajak Anjlok: Salah Satu...</td>\n",
       "      <td>https://www.tempo.co/ekonomi/cari-sebab-peneri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Diskon Tarif Listrik Dinilai sebagai Kebijakan...</td>\n",
       "      <td>https://www.tempo.co/ekonomi/diskon-tarif-list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Alasan Anindya Bakrie Kukuhkan Sebanyak 2.800 ...</td>\n",
       "      <td>https://www.tempo.co/ekonomi/alasan-anindya-ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                judul  \\\n",
       "0   Seknas Fitra: Makan Bergizi Gratis Belum Dongk...   \n",
       "1   Hingga 21 Mei, Anggaran Makan Bergizi Gratis S...   \n",
       "2   Korban Keracunan MBG Lebih Besar dari Klaim Pr...   \n",
       "3   Sejumlah Titik Kritis dalam Program MBG, Menur...   \n",
       "4   Bos BGN Membantah Raffi Ahmad Kelola 300 Dapur...   \n",
       "..                                                ...   \n",
       "95  Penerima Manfaat Makan Bergizi Gratis hingga M...   \n",
       "96   Peluncuran Dapur Satuan Pelayanan Pemenuhan Gizi   \n",
       "97  Cari Sebab Penerimaan Pajak Anjlok: Salah Satu...   \n",
       "98  Diskon Tarif Listrik Dinilai sebagai Kebijakan...   \n",
       "99  Alasan Anindya Bakrie Kukuhkan Sebanyak 2.800 ...   \n",
       "\n",
       "                                                 link  \n",
       "0   https://www.tempo.co/ekonomi/seknas-fitra-maka...  \n",
       "1   https://www.tempo.co/ekonomi/hingga-21-mei-ang...  \n",
       "2   https://www.tempo.co/politik/korban-keracunan-...  \n",
       "3   https://www.tempo.co/politik/sejumlah-titik-kr...  \n",
       "4   https://www.tempo.co/ekonomi/bos-bgn-membantah...  \n",
       "..                                                ...  \n",
       "95  https://www.tempo.co/ekonomi/penerima-manfaat-...  \n",
       "96  https://www.tempo.co/foto/arsip/peluncuran-dap...  \n",
       "97  https://www.tempo.co/ekonomi/cari-sebab-peneri...  \n",
       "98  https://www.tempo.co/ekonomi/diskon-tarif-list...  \n",
       "99  https://www.tempo.co/ekonomi/alasan-anindya-ba...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_tempo_search_selenium(\"makan bergizi gratis\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e6359",
   "metadata": {},
   "source": [
    "## 3. Scraping artikel dalam URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fungsi melakukan scraping data dari hasil crawling URL Tempo, masukkan csv\n",
    "def scrape_tempo_dari_csv(path_csv: str) -> pd.DataFrame:\n",
    "    # Membaca CSV hasil scraping link\n",
    "    df_links = pd.read_csv(path_csv)\n",
    "\n",
    "    # Memastikan kolom 'link' ada\n",
    "    if 'link' not in df_links.columns:\n",
    "        raise ValueError(\"CSV tidak mengandung kolom 'link'.\")\n",
    "\n",
    "    hasil_semua = []\n",
    "    for i, row in tqdm(df_links.iterrows(), total=len(df_links)):\n",
    "        url = row['link']\n",
    "        df_artikel = scrape_tempo(url) #memanggil dan menjalankan fungsi scrape_tempo satu artikel\n",
    "        if df_artikel is not None:\n",
    "            hasil_semua.append(df_artikel)\n",
    "\n",
    "    # Gabungkan semua DataFrame\n",
    "    if hasil_semua:\n",
    "        df_final = pd.concat(hasil_semua, ignore_index=True)\n",
    "        df_final.to_csv('./files/tempo_semua_artikel.csv', index=False, encoding='utf-8-sig')\n",
    "        print(\"Selesai menyimpan semua artikel.\")\n",
    "        return df_final\n",
    "    else:\n",
    "        print(\"Tidak ada artikel yang berhasil di-scrape.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de1ea70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:37<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selesai menyimpan semua artikel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>sub_judul</th>\n",
       "      <th>isi</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>jam</th>\n",
       "      <th>kategori</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seknas Fitra: Makan Bergizi Gratis Belum Dongk...</td>\n",
       "      <td>Karena memaksakan Makan Bergizi Gratis pemerin...</td>\n",
       "      <td>TEMPO.CO,Jakarta-Sekretariat Nasional Forum In...</td>\n",
       "      <td>24 Mei 2025</td>\n",
       "      <td>17.24 WIB</td>\n",
       "      <td>Bisnis</td>\n",
       "      <td>https://www.tempo.co/ekonomi/seknas-fitra-maka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hingga 21 Mei, Anggaran Makan Bergizi Gratis S...</td>\n",
       "      <td>Hingga 21 Mei 2025 kementerian keuangan telah ...</td>\n",
       "      <td>TEMPO.CO,Jakarta- Wakil Menteri Keuangan Suaha...</td>\n",
       "      <td>23 Mei 2025</td>\n",
       "      <td>16.11 WIB</td>\n",
       "      <td>Bisnis</td>\n",
       "      <td>https://www.tempo.co/ekonomi/hingga-21-mei-ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Korban Keracunan MBG Lebih Besar dari Klaim Pr...</td>\n",
       "      <td>Tim Cek Fakta Tempo menemukan angka keracunan ...</td>\n",
       "      <td>TEMPO.CO,Jakarta-PRESIDEN Prabowo Subianto men...</td>\n",
       "      <td>23 Mei 2025</td>\n",
       "      <td>14.10 WIB</td>\n",
       "      <td>Politik</td>\n",
       "      <td>https://www.tempo.co/politik/korban-keracunan-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sejumlah Titik Kritis dalam Program MBG, Menur...</td>\n",
       "      <td>Kepala BPOM mendorong keterlibatan instansinya...</td>\n",
       "      <td>KOMISI IX DPR mendesak Badan Pengawas Obat dan...</td>\n",
       "      <td>23 Mei 2025</td>\n",
       "      <td>10.13 WIB</td>\n",
       "      <td>Politik</td>\n",
       "      <td>https://www.tempo.co/politik/sejumlah-titik-kr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bos BGN Membantah Raffi Ahmad Kelola 300 Dapur...</td>\n",
       "      <td>Kabar Raffi Ahmad mendapatkan jatah mengelola ...</td>\n",
       "      <td>TEMPO.CO,Jakarta- Kepala Badan Gizi Nasional (...</td>\n",
       "      <td>22 Mei 2025</td>\n",
       "      <td>19.30 WIB</td>\n",
       "      <td>Bisnis</td>\n",
       "      <td>https://www.tempo.co/ekonomi/bos-bgn-membantah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Seknas Fitra: Makan Bergizi Gratis Belum Dongk...   \n",
       "1  Hingga 21 Mei, Anggaran Makan Bergizi Gratis S...   \n",
       "2  Korban Keracunan MBG Lebih Besar dari Klaim Pr...   \n",
       "3  Sejumlah Titik Kritis dalam Program MBG, Menur...   \n",
       "4  Bos BGN Membantah Raffi Ahmad Kelola 300 Dapur...   \n",
       "\n",
       "                                           sub_judul  \\\n",
       "0  Karena memaksakan Makan Bergizi Gratis pemerin...   \n",
       "1  Hingga 21 Mei 2025 kementerian keuangan telah ...   \n",
       "2  Tim Cek Fakta Tempo menemukan angka keracunan ...   \n",
       "3  Kepala BPOM mendorong keterlibatan instansinya...   \n",
       "4  Kabar Raffi Ahmad mendapatkan jatah mengelola ...   \n",
       "\n",
       "                                                 isi      tanggal        jam  \\\n",
       "0  TEMPO.CO,Jakarta-Sekretariat Nasional Forum In...  24 Mei 2025  17.24 WIB   \n",
       "1  TEMPO.CO,Jakarta- Wakil Menteri Keuangan Suaha...  23 Mei 2025  16.11 WIB   \n",
       "2  TEMPO.CO,Jakarta-PRESIDEN Prabowo Subianto men...  23 Mei 2025  14.10 WIB   \n",
       "3  KOMISI IX DPR mendesak Badan Pengawas Obat dan...  23 Mei 2025  10.13 WIB   \n",
       "4  TEMPO.CO,Jakarta- Kepala Badan Gizi Nasional (...  22 Mei 2025  19.30 WIB   \n",
       "\n",
       "  kategori                                               link  \n",
       "0   Bisnis  https://www.tempo.co/ekonomi/seknas-fitra-maka...  \n",
       "1   Bisnis  https://www.tempo.co/ekonomi/hingga-21-mei-ang...  \n",
       "2  Politik  https://www.tempo.co/politik/korban-keracunan-...  \n",
       "3  Politik  https://www.tempo.co/politik/sejumlah-titik-kr...  \n",
       "4   Bisnis  https://www.tempo.co/ekonomi/bos-bgn-membantah...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = scrape_tempo_dari_csv(\"./files/tempo_links.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8879e2c",
   "metadata": {},
   "source": [
    "## Next: Analisis Sentimen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
